%run ./.setup/learner_setup 
# Standard
import os
import json
import pandas as pd
from dotenv import load_dotenv
import httpx

# LangChain Core
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableLambda, RunnablePassthrough
from langchain_core.documents import Document

# LangChain OpenAI
from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings

# Vector Store
from langchain.vectorstores import Chroma

# Retrieval Strategies
from langchain.retrievers import ContextualCompressionRetriever
from langchain.retrievers.document_compressors import EmbeddingsFilter

# Evaluation
from langchain.evaluation import load_evaluator,EvaluatorType
from langchain.evaluation.schema import EvaluatorType

from IPython.display import display, Markdown
from tenacity import (
    retry,
    stop_after_attempt,
    wait_random_exponential,
)





def get_access_token():
    auth = "https://api.uhg.com/oauth2/token"
    scope = "https://api.uhg.com/.default"
    grant_type = "client_credentials"


    with httpx.Client() as client:
        body = {
            "grant_type": grant_type,
            "scope": scope,
            "client_id": dbutils.secrets.get(scope="AIML_Training", key="client_id"),
            "client_secret": dbutils.secrets.get(scope="AIML_Training", key="client_secret"),
        }
        headers = {"Content-Type": "application/x-www-form-urlencoded"}
        resp = client.post(auth, headers=headers, data=body, timeout=60)
        access_token = resp.json()["access_token"]
        return access_token


load_dotenv('./UAIS.env')


AZURE_OPENAI_ENDPOINT = os.environ["AZURE_OPENAI_ENDPOINT"]
OPENAI_API_VERSION = os.environ["OPENAI_API_VERSION"]
EMBEDDINGS_DEPLOYMENT_NAME = os.environ["EMBEDDINGS_DEPLOYMENT_NAME"]
MODEL_DEPLOYMENT_NAME = os.environ["MODEL_DEPLOYMENT_NAME"]
PROJECT_ID = os.environ['PROJECT_ID']

chat_client = AzureChatOpenAI(
    azure_endpoint=AZURE_OPENAI_ENDPOINT,
    api_version=OPENAI_API_VERSION,
    azure_deployment=MODEL_DEPLOYMENT_NAME,
    temperature=0,
    azure_ad_token=get_access_token(),
    default_headers={
        "projectId": PROJECT_ID
    }
)


embeddings_client = AzureOpenAIEmbeddings(
    azure_endpoint=AZURE_OPENAI_ENDPOINT,
    api_version=OPENAI_API_VERSION,
    azure_deployment=EMBEDDINGS_DEPLOYMENT_NAME,
    azure_ad_token=get_access_token(),
    default_headers={
        "projectId": PROJECT_ID
    }
)
# Load your dataset
dataset = pd.read_csv("/Workspace/Users/atul_gupta@optum.com/Capstone/Data/capstone1_rag_dataset.csv")

# Create a vector database from  documents.
# Enables semantic search over clinical research content.
vector_db = Chroma.from_texts(
    texts= dataset['context'].tolist(),              # List of document texts
    collection_name='capstone_rag_db',        # Collection name
    embedding=embeddings_client,              # Embedding model for vectorization
)
#  Define Retrieval Strategies


basic_retriever = vector_db.as_retriever(search_kwargs={"k": 3})
threshold_filter = EmbeddingsFilter(embeddings=embeddings_client, similarity_threshold=0.75)
threshold_retriever = ContextualCompressionRetriever(base_compressor=threshold_filter, base_retriever=basic_retriever)

prompt = ChatPromptTemplate.from_template("""You are a clinical assistant. Use the following context to answer the question.
If the answer is not contained in the context, say "I'm not sure based on the provided information."
Context:
{context}
Question: {question}
Answer:""")


#  RAG Pipeline
def build_rag_chain(retriever):return ({"context": retriever, "question": RunnablePassthrough()}| prompt| chat_client| StrOutputParser())

#  Evaluation on Validation Dataset
validation_df = pd.read_csv("/Workspace/Users/atul_gupta@optum.com/Capstone/Data/capstone1_rag_validation.csv")
questions = validation_df["question"].tolist()
reference_contexts = validation_df["reference_context"].tolist()
reference_answers = validation_df["reference_answer"].tolist()

retrieval_evaluator = load_evaluator(EvaluatorType.CONTEXT_QA,llm=chat_client,k=3)

# Run evaluation
retrieval_results = retrieval_evaluator.evaluate_strings(
    input=questions,
    prediction=["\n".join([doc.page_content for doc in basic_retriever.invoke(q)]) for q in questions],
    reference=reference_contexts
    )



# Print top-level keys

print(" Retrieval Evaluation Summary")
print(f" Reasoning: {retrieval_results['reasoning']}")
print(f" Score: {retrieval_results['score']}")
print(f" Value: {retrieval_results['value']}")







# generation_chain = build_rag_chain(basic_retriever)
# generated_answers = [generation_chain.invoke(q) for q in questions]



# Print a few results from validation
#for i in range(3):
    #print("Q:", questions[i])
    #print("A:", generated_answers[i])
    #print()


# --- Hybrid Retrieval Strategy (Semantic + Keyword) ---

from langchain.retrievers import EnsembleRetriever, BM25Retriever

# Create a keyword-based retriever using BM25
bm25_retriever = BM25Retriever.from_texts(dataset['context'].tolist())

# Top-k documents
bm25_retriever.k = 3

# Combine with existing semantic retriever
hybrid_retriever = EnsembleRetriever(
    retrievers=[basic_retriever, bm25_retriever],
    # Equal weight to both retrievers
    weights=[0.5, 0.5]
    )

# Build RAG chain using hybrid retriever
hybrid_generation_chain = build_rag_chain(hybrid_retriever)


# Print a few results from validation
for i in range(3):
    print("Q:", questions[i])
    print("A:", hybrid_generation_chain.invoke(questions[i]))
    print()




#  Run on Test Dataset and Save Submission
test_df = pd.read_csv("/Workspace/Users/atul_gupta@optum.com/Capstone/Data/capstone1_rag_test_questions.csv")
test_questions = test_df["question"].tolist()

submission_data = []
for q in test_questions:
    docs = hybrid_retriever.invoke(q)
    doc_texts = [doc.page_content for doc in docs]
    answer = hybrid_generation_chain.invoke(q)
    submission_data.append({
         "question": q,
         "retrieved_documents": doc_texts,
         "generated_answer": answer
         })

submission_df = pd.DataFrame(submission_data)
submission_df.to_csv("submission.csv", index=False)
print(" submission.csv has been saved.")
